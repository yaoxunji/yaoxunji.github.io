<!doctype html>
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin SEO -->





<title>Jixun Yao (ÂßöÁªßÁè£) - Homepage</title>







<meta property="og:locale" content="en">
<meta property="og:site_name" content="Jixun Yao (ÂßöÁªßÁè£)">
<meta property="og:title" content="Jixun Yao (ÂßöÁªßÁè£)">


  <link rel="canonical" href="https://github.com/pages/yaoxunji/yaoxunji.github.io/">
  <meta property="og:url" content="https://github.com/pages/yaoxunji/yaoxunji.github.io/">



  <meta property="og:description" content="">









<!-- end SEO -->


<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="assets/css/main.css">

<meta http-equiv="cleartype" content="on">
<head>
  <base target="_blank">
</head>
    <link rel="apple-touch-icon" sizes="180x180" href="images/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="images/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="images/favicon-16x16.png">
<link rel="manifest" href="images/site.webmanifest">

<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg masthead__menu-home-item"><a href="#about-me">Homepage</a></li>
          
            <li class="masthead__menu-item"><a href="/#about-me">About Me</a></li>
          
            <li class="masthead__menu-item"><a href="/#-research-area">Research Area</a></li>
          
            <li class="masthead__menu-item"><a href="/#-internships">Internships</a></li>
          
            <li class="masthead__menu-item"><a href="/#-publications">Publications</a></li>
          
            <li class="masthead__menu-item"><a href="/#-honors-and-awards">Honors and Awards</a></li>
          
            <li class="masthead__menu-item"><a href="/#-service">Service</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    <div id="main" role="main">
      
  <div class="sidebar sticky">
  

<div itemscope itemtype="http://schema.org/Person" class="profile_box">

  <div class="author__avatar">
    <img src="images/android-chrome-512x512.png" class="author__avatar" alt="Jixun Yao (ÂßöÁªßÁè£)">
  </div>

  <div class="author__content">
    <h3 class="author__name">Jixun Yao (ÂßöÁªßÁè£)</h3>
    <p class="author__bio">Ph.D. Student @ Audio, Speech and Language Processing Group (ASLP@NPU), School of Computer Science, Northwestern Polytechnical University</p>
  </div>

  <div class="author__urls-wrapper">
    <!-- <button class="btn btn--inverse">More Info & Contact</button> -->
    <ul class="author__urls social-icons">
      
        <li><div style="white-space: normal; margin-bottom: 1em;"></div></li>
      
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> China</li>
      
      
      
      
        <li><a href="mailto:yaojx@mail.nwpu.edu.cn"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i> Email</a></li>
      
      
       
      
      
      
      
      
        <li><a href="https://dblp.uni-trier.de/pid/291/0045.html"><i class="ai ai-dblp ai-fw" aria-hidden="true"></i> DBLP</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://scholar.google.co.uk/citations?user=KjcXd6cAAAAJ"><i class="fas fa-fw fa-graduation-cap"></i> Google Scholar</a></li>
      
      
      
      
      
    </ul>
      <div class="author__urls_sm">
      
      
        <a href="mailto:yaojx@mail.nwpu.edu.cn"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i></a>
      
      
       
      
      
      
      
      
        <a href="https://dblp.uni-trier.de/pid/291/0045.html"><i class="ai ai-dblp ai-fw" aria-hidden="true"></i></a>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <a href="https://scholar.google.co.uk/citations?user=KjcXd6cAAAAJ"><i class="fas fa-fw fa-graduation-cap"></i></a>
      
      
      
      
      
    </div>
  </div>
</div>

  
  </div>

    
      <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
        <meta itemprop="headline" content="">
        <div class="page__inner-wrap">
          <section class="page__content" itemprop="text">
            
<p><span class="anchor" id="about-me"></span></p>

<!-- Jixun Yao -->

<p>I‚Äôm a four-year Ph.D. student at the Northwestern Polytechnical University, supervised by Prof. <a href="http://lxie.npu-aslp.org/">Lei Xie</a>.</p>

<!-- My research interest includes speech synthesis, voice conversion and speaker anonymization. I have published more than 20 papers at the top international speech conferences and journal with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fyaoxunji%2Fyaoxunji.github.io%40google-scholar-stats%2Fgs_data_shieldsio.json&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>). -->

<p>My research interest includes speech synthesis, voice conversion and speaker anonymization. I have published more than 20 papers at the top international speech conferences and journal.</p>

<h1 id="-research-area">üîç Research Area</h1>
<p><strong>Speech Processing</strong>: Voice Conversion, Text-to-Speech, Speaker Anonymization, Expressive Speech Synthesis</p>

<p><strong>Large Language Models</strong>: Speech LLMs, Speech Tokenizer, Diffusion Models</p>

<!-- **Speech Privacy**: -->

<h1 id="-internships">üíª Internships</h1>
<ul>
  <li><em>2024.03 - Now</em>, Nanyang Technological University, Singapore (supervised by Prof. <a href="https://aseschng.github.io/intro1.html">Eng-Siong Chng</a>).</li>
  <li><em>2022.12 - 2024.02</em>, Everest Team - Ximalaya, China.</li>
</ul>

<!-- # üî• News
- *2024.03*: &nbsp;üéâüéâ I exchange to Nanyang Technological University supervised by Prof. [Eng-Siong Chng](https://aseschng.github.io/intro1.html). -->

<h1 id="-publications">üìù Publications</h1>

<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div> -->

<p>2024:</p>

<ul>
  <li>
    <p><span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">IEEE TASLP</span> Distinctive and Natural Speaker Anonymization via Singular Value Transformation-Assisted Matrix. <strong>J Yao</strong>, Y Lei, Q Wang, P Guo, Z Ning, L Xie. <a href="https://arxiv.org/pdf/2405.10786">[PDF]</a></p>
  </li>
  <li>
    <p><span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">ICASSP 2024</span> PromptVC: Flexible stylistic voice conversion in latent space driven by natural language prompts. <strong>J Yao</strong>, Y Yang, Y Lei, Z Ning, Y Hu, Y Pan, J Yin, H Zhou, H Lu, L Xie. <a href="https://arxiv.org/pdf/2309.09262">[PDF]</a>  <a href="https://yaoxunji.github.io/prompt_vc/">[DemoPage]</a></p>
  </li>
  <li>
    <p><span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">ICASSP 2024</span> Dualvc 2: Dynamic masked convolution for unified streaming and non-streaming voice conversion. Z Ning, Y Jiang, P Zhu, S Wang, <strong>J Yao</strong>, L Xie, M Bi. <a href="https://arxiv.org/pdf/2309.15496">[PDF]</a>  <a href="https://dualvc.github.io/dualvc2/">[DemoPage]</a></p>
  </li>
  <li>
    <p><span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">ICASSP 2024</span> GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio Pretraining for Accurate Speech Emotion Recognition. Y Pan, Y Hu, Y Yang, W Fei, <strong>J Yao</strong>, H Lu, L Ma, J Zhao. <a href="https://arxiv.org/pdf/2306.07848">[PDF]</a></p>
  </li>
  <li>
    <p><span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">INTERSPEECH 2024</span> DualVC 3: Leveraging Language Model Generated Pseudo Context for End-to-end Low Latency Streaming Voice Conversion. Z Ning, S Wang, P Zhu, Z Wang, <strong>J Yao</strong>, L Xie, M Bi. <a href="https://arxiv.org/pdf/2406.07846">[PDF]</a>  <a href="https://nzqian.github.io/dualvc3/">[DemoPage]</a></p>
  </li>
</ul>

<p>2023:</p>
<ul>
  <li>
    <p><span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">ICASSP 2023</span> Preserving background sound in noise-robust voice conversion via multi-task learning. <strong>J Yao</strong>, Y Lei, Q Wang, P Guo, Z Ning, L Xie, H Li, J Liu, D Xie. <a href="https://arxiv.org/pdf/2211.03036">[PDF]</a>  <a href="https://yaoxunji.github.io/background_sound_vc/">[DemoPage]</a></p>
  </li>
  <li>
    <p><span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">ICASSP 2023</span> Distinguishable speaker anonymization based on formant and fundamental frequency scaling. <strong>J Yao</strong>, Q Wang, Y Lei, P Guo, L Xie, N Wang, J Liu. <a href="https://arxiv.org/pdf/2211.03038">[PDF]</a></p>
  </li>
  <li>
    <p><span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">ICASSP 2023</span> Expressive-vc: Highly expressive voice conversion with attention fusion of bottleneck and perturbation features. Z Ning, Q Xie, P Zhu, Z Wang, L Xue, <strong>J Yao</strong>, L Xie, M Bi. <a href="https://arxiv.org/pdf/2211.04710">[PDF]</a>  <a href="https://nzqian.github.io/Expressive-VC.github.io/">[DemoPage]</a></p>
  </li>
  <li>
    <p><span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">IEEE TASLP</span> Timbre-reserved Adversarial Attack in Speaker Identification. Q Wang, <strong>J Yao</strong>, L Zhang, P Guo, L Xie. <a href="https://arxiv.org/pdf/2309.00929">[PDF]</a></p>
  </li>
  <li>
    <p><span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">ASRU 2023</span> Salt: Distinguishable Speaker Anonymization Through Latent Space Transformation. Y Lv, <strong>J Yao</strong>, P Chen, H Zhou, H Lu, L Xie. <a href="https://arxiv.org/pdf/2310.05051">[PDF]</a> <a href="https://github.com/BakerBunker/SALT">[Code]</a></p>
  </li>
  <li>
    <p><span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">INTERSPEECH 2023</span> Pseudo-Siamese Network based Timbre-reserved Black-box Adversarial Attack in Speaker Identification. Q Wang, <strong>J Yao</strong>, Z Wang, P Guo, L Xie. <a href="https://arxiv.org/pdf/2305.19020">[PDF]</a></p>
  </li>
  <li>
    <p><span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">INTERSPEECH 2023</span> Dualvc: Dual-mode voice conversion using intra-model knowledge distillation and hybrid predictive coding. Z Ning, Y Jiang, P Zhu, <strong>J Yao</strong>, S Wang, L Xie, M Bi. <a href="https://arxiv.org/pdf/2305.12425">[PDF]</a> <a href="https://dualvc.github.io/">[DemoPage]</a></p>
  </li>
  <li>
    <p><span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">AAAI 2023</span> UniSyn: an end-to-end unified model for text-to-speech and singing voice synthesis. Y Lei, S Yang, X Wang, Q Xie, <strong>J Yao</strong>, L Xie, D Su. <a href="https://arxiv.org/pdf/2212.01546">[PDF]</a> <a href="https://leiyi420.github.io/UniSyn/">[DemoPage]</a></p>
  </li>
  <li>
    <p><span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">DADA@IJCAI 2023</span> The NPU-ASLP System for Deepfake Algorithm Recognition in ADD 2023 Challenge. Z Wang, Q Wang, <strong>J Yao</strong>, L Xie. <a href="http://addchallenge.cn/files/2023/pdf/p64-wang.pdf">[PDF]</a></p>
  </li>
  <li>
    <p><span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">SMAC 2023</span> Exploring the power of cross-contextual large language model in mimic emotion prediction. G Yi, Y Yang, Y Pan, Y Cao, <strong>J Yao</strong>, X Lv, C Fan, Z Lv, J Tao, S Liang, H Lu. <a href="https://dl.acm.org/doi/10.1145/3606039.3613109">[PDF]</a></p>
  </li>
</ul>

<p>2022:</p>

<ul>
  <li><span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">VPC 2022</span> NWPU-ASLP system for the voiceprivacy 2022 challenge. <strong>J Yao</strong>, Q Wang, L Zhang, P Guo, Y Liang, L Xie. <a href="https://arxiv.org/pdf/2209.11969">[PDF]</a></li>
</ul>

<h1 id="-honors-and-awards">üéñ Honors and Awards</h1>
<ul>
  <li><em>2023.06</em> The 4th place winner for the Deepfake Algorithm Recognition task in the Audio Deepfake Detection (ADD) Challenge @ IJCAI Workshop, 2023.</li>
  <li><em>2022.09</em> The 1th place winner in the VoicePrivacy Challenge (VPC) 2022 @ INTERSPEECH Workshop, 2024</li>
</ul>

<!-- # üìñ Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

<h1 id="-service">üí¨ Service</h1>
<ul>
  <li>Reviewer
    <ul>
      <li>IEEE TASLP</li>
      <li>IEEE SPL</li>
      <li>Speech Communication</li>
      <li>ICASSP `2024</li>
      <li>INTERSPEECH `2024</li>
      <li>ACM MM `2024</li>
    </ul>
  </li>
  <li>Organizer
    <ul>
      <li><a href="https://www.magicdatatech.com/iscslp-2024">Conversational Voice Clone Challenge (CoVoC)</a> @ ISCSLP 2024</li>
    </ul>
  </li>
</ul>

<p>Thanks for the template of <a href="https://github.com/RayeRen/acad-homepage.github.io">acad-homepage.github.io</a></p>

<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=yj7G4uPjZTwu7X50zzhTW14ybx6QOClZ1fWK16GJDpU&amp;cl=ffffff&amp;w=a"></script>


          </section>
        </div>
      </article>
    </div>

    <script src="assets/js/main.min.js"></script>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id="></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', "");
</script>


<script>
    $(document).ready(function () {
        
        var gsDataBaseUrl = 'https://cdn.jsdelivr.net/gh/yaoxunji/yaoxunji.github.io@'
        
        $.getJSON(gsDataBaseUrl + "google-scholar-stats/gs_data.json", function (data) {
            var totalCitation = data['citedby']
            document.getElementById('total_cit').innerHTML = totalCitation;
            var citationEles = document.getElementsByClassName('show_paper_citations')
            Array.prototype.forEach.call(citationEles, element => {
                var paperId = element.getAttribute('data')
                var numCitations = data['publications'][paperId]['num_citations']
                element.innerHTML = '| Citations: ' + numCitations;
            });
        });
    })
</script>


  </body>
</html>
